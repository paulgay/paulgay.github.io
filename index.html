<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" encoding="ISO-8859-1">
<head>
<title>Paul Gay home page</title>
<meta http-equiv="content-type" content="text/html;charset=iso-8859-2" />
<link rel="stylesheet" href="images/style.css" type="text/css" />
<link rel="stylesheet" href="common.css" type="text/css" />
</head>
<body>
	<script>
	
	var abstracts = {
	accv_title:'<cite>Visual Graphs from Motion (VGfM): Scene understanding with object geometry reasoning</cite> <br> 2018 ACCV, (Asian Conference on Computer Vision) ',
        accv_abstract:'<a href="https://arxiv.org/pdf/1807.05933.pdf">pdf</a> <a href="https://github.com/paulgay/VGfM">code</a> <br> Recent approaches on visual scene understanding attempt to build a scene graph -- a computational representation of objects and their pairwise relationships. Such rich semantic representation is very appealing, yet difficult to obtain from a single image, especially when considering complex spatial arrangements in the scene. Differently, an image sequence conveys useful information using the multi-view geometric relations arising from camera motion. Indeed, in such cases, object relationships are naturally related to the 3D scene structure. To this end, this paper proposes a system that first computes the geometrical location of objects in a generic scene and then efficiently constructs scene graphs from video by embedding such geometrical reasoning. Such compelling representation is obtained using a new model where geometric and visual features are merged using an RNN framework. We report results on a dataset we created for the task of 3D scene graph generation in multiple views.', 
	frontiers_title:'<cite> CRF-Based Context Modeling for Person Identification in Broadcast Videos </cite> <br> 2015 Frontiers journal in ICT ',
        frontiers_abstract:'Paul Gay, Sylvain Meignie Paul Del√©glise and Jean-Marc Odobez <p>  We are investigating the problem of speaker and face identification in broadcast videos. Identification is performed by associating automatically extracted names from overlaid texts with speaker and face clusters. We aimed at exploiting the structure of news videos to solve name/cluster association ambiguities and clustering errors. The proposed approach combines iteratively two conditional random fields (CRF). The first CRF performs the person diarization (joint temporal segmentation, clustering, and association of voices and faces) jointly over the speech segments and the face tracks. It benefits from contextual information being extracted from the image backgrounds and the overlaid texts. The second CRF associates names with person clusters, thanks to co-occurrence statistics. Experiments conducted on a recent and substantial public dataset containing reports and debates demonstrate the interest and complementarity of the different modeling steps and information sources: the use of these elements enables us to obtain better performances in clustering and identification, especially in studio scenes.</p> ', 
        iccv_title:'<cite>Probabilistic Structure from Motion with Objects</cite> <br> 2017 ICCV, (International Conference on Computer Vision) ',
	iccv_abstract:'<a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Gay_Probabilistic_Structure_From_ICCV_2017_paper.pdf">pdf</a> <a href="https://gitlab.iit.it/pgay/affine_psfmo">code</a> <br> Paul Gay, Vaibhav Bansal, Cosimo Rubino, Alessio Del Bue <p> This paper proposes a probabilistic approach to recover affine camera calibration and objects position/occupancy from multi-view images using solely the information from image detections. We show that remarkable object localisation and volumetric occupancy can be recovered by including both geometrical constraints and prior information given by objects CAD models from the ShapeNet dataset. This can be done by recasting the problem in the context of a probabilistic framework based on PPCA that enforces both geometrical constraints and the associated semantic given by the object category extracted by the object detector. We present results on synthetic data and extensive real evaluation on the ScanNet datasets on more than 1200 image sequences to show the validity of our approach in realistic scenarios. In particular, we show that 3D statistical priors are key to obtain reliable reconstruction especially when the input detections are noisy, a likely case in real scenes.</p>' ,
	cviu_title:'<cite> Factorization based Structure from Motion with Object Priors</cite> <br>  2017 CVIU (Computer Vision and Image Understanding) ', 
        cviu_abstract:'<a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314217301893">paper</a> <br> Paul Gay, Cosimo Rubino, Marco Crocco, Alessio Del Bue <p> This paper presents an efficient framework to include the information of objects position in classical multi-view geometry problems for 3D reconstruction. In particular, we present two main contributions to Structure from Motion (SfM) using factorization methods for the affine camera case. First, we introduce a method based on factorization that extends the classical 3D point cloud reconstruction based on 2D point correspondences to objects using detection correspondences. In this case, objects are approximated as quadrics in 3D (or more specifically as ellipsoids) and therefore projected as conics in 2D onto the image plane. Therefore, instead of having 2D point to point correspondences, we solve a conic to conic correspondence problem in the setting of affine factorization methods. The solution to this problem provides a 3D location/occupancy of the object together with an affine camera calibration. This is shown to be a generalisation of the standard Tomasi and Kanade factorization method with rigid objects. Secondly, we use the estimated object locations/occupancies to robustly estimate the 3D point cloud from 2D point correspondences by constructing a prior that relates 2D points locations and the positions of the object ellipsoids in 3D. This is done by recasting the problem as a probabilistic matrix factorization where the priors are not generic but truly representative of the scene structure as a composition of objects. In particular we show that by using objects to points relations, we achieve compelling results with high rate of missing data and noisy 2D data, a common occurrence when dealing with man-made textureless objects.</p>',
	cbmi_title:'<cite>Comparison of Two Methods for Unsupervised Person Identification in TV Shows</cite> <br> 2014 CBMI (IEEE worshop on Content based Multimedia Indexing) ',
	cbmi_abstract:' <a href="http://publications.idiap.ch/downloads/papers/2014/Gay_CBMI_2014.pdf">pdf</a> <br>  Paul Gay, Gregor Dupuy, Jean-Marc Odobez, Meignier Sylvain and Paul Deleglise <p> We address the task of identifying people appearing in TV shows. The target persons are all people whose identity is said or written, like the journalists and the well known people, as politicians, athletes, celebrities, etc. In our approach, overlaid names displayed on the images are used to identify the persons without any use of biometric models for the speakers and the faces. Two identification methods are evaluated as part of the REPERE French evaluation campaign. The first one relies on co-occurrence times between overlay person names and speaker/face clusters, and rule-based decisions which assign a name to each monomodal cluster. The second method uses a Conditionnal Random Field (CRF) which combine different types of co-occurrence statistics and pair-wised constraints to jointly identify speakers and faces.</p>',
	icip_abstract:' <a href="http://publications.idiap.ch/downloads/papers/2015/Gay_ICIP_2014.pdf">pdf</a> <br> Paul Gay, Elie Khoury, Sylvain Meignier, Jean-Marc Odobez, and Paul Deleglise <p>We investigate the problem of face identification in broadcast programs where people names are obtained from text overlays automatically processed with Optical Character Recognition (OCR) and further linked to the faces throughout the video.  To solve the face-name association and propagation, we propose a novel approach that combines the positive effects of two Conditional Random Field (CRF) models: a CRF for person diarization (joint temporal segmentation and association of voices and faces) that benefit from the combination of multiple cues including as main contributions the use of identification sources (OCR appearances) and recurrent local face visual background (LFB) playing the role of a namedness feature; a second CRF for the joint identification of the person clusters that improves identification performance thanks to the use of further diarization statistics.  Experiments conducted on a recent and substantial public dataset of 7 different shows  demonstrate  the  interest  and  complementarity  of  the different modeling steps and information sources, leading to state of the art result </p>',
	icip_title:'<cite>A conditional random field approach in broadcast news using overlaid texts</cite> <br> 2014 ICIP (IEEE International Conference on Image Processing)',
	icassp_abstract:' <a href="http://publications.idiap.ch/downloads/papers/2014/Gay_ICASSP_2014.pdf">pdf</a> <br> Paul Gay, Elie Khoury, Sylvain Meignier, Jean-Marc Odobez, and Paul Deleglise <p>We investigate the problem of audio-visual (AV) person diarization in broadcast data.  That is, automatically associate the faces and voices of people and determine when they appear or speak in the video.  The contributions are twofolds. First, we formulate the problem within a novel CRF framework  that  simultaneously  performs  the  AV  association of voices and face clusters to build AV person models, and the joint  segmentation  of  the  audio  and  visual  streams  using  a set of AV cues and their association strength.  Secondly, we use for this AV association strength a score that does not only rely on lips activity,  but also on contextual visual information (face size, position, number of detected faces,...)  that leads to more reliable association measures.  Experiments on 6  hours  of  broadcast  data  show  that  our  framework  is  able to improve the AV-person diarization especially for speaker segments erroneously labeled in the mono-modal case.</p>',
	icassp_title:'<cite>A conditional random field approach for audio-visual people diarization</cite> <br> 2014 ICASSP (International Conference on Acoustic Speech and Signal Processing)',
	interspeech_abstract:' <a href="http://publications.idiap.ch/downloads/papers/2013/Rouvier_INTERSPEECH_2013.pdf">pdf</a> <a href="https://projets-lium.univ-lemans.fr/spkdiarization/">code</a>  <br> Mickael Rouvier, Gregor Dupuy, Paul Gay, Elie Khoury, Teva Merlin and Sylvain Meignier <p>This paper presents the LIUM open-source speaker diarization toolbox, mostly dedicated to broadcast news. This tool includes both Hierarchical Agglomerative Clustering using well-known measures  such  as  BIC  and  CLR,  and  the  new  ILP  clustering algorithm  using  i-vectors. Diarization  systems  are  tested  on the French evaluation data from ESTER, ETAPE and REPERE campaigns </p>',
	interspeech_title:'<cite> An open-source state-of-the-art toolbox for broadcast news diarization</cite> <br> 2013 INTERSPEECH (Conference of the International Speech Communication Association)',
	icmr_abstract:' <a href="http://publications.idiap.ch/downloads/papers/2013/Khoury_ACMICMR_2013.pdf">pdf</a> <br> Elie Khoury, Paul Gay and Jean-Marc Odobez <p>This paper addresses face diarization in videos, that is, deciding which face appears and when in the video. To achieve this face-track clustering task, we propose a hierarchical approach combining the strength of two complementary measures:  (i) a pairwise matching similarity relying on local interest points allowing the accurate clustering of faces tracks captured in similar conditions, a situation typically found in temporally close shots of broadcast videos or in talk-shows</p>',
	icmr_title:'<cite>Fusing matching and biometric similarity measures for face diarization in video</cite> <br> 2013 ICMR (IEEE International Conference on Multimedia Retrieval)',
	ronan_abstract:' <a href="https://hal.archives-ouvertes.fr/hal-00945357/document">pdf</a> <br> Ronan Fablet, Paul Gay, Salvador Peraltilla, Cecilia Pena, Ramiro Castillo and Arnaud Bertrand <p>Whereas    fisheries    acoustics    data    processing    mainly    focused    on    the    detection, characterization   and   recognition   of   individual   fish   schools,   here   we   addressed   the characterization and discrimination of fish school clusters. The proposed scheme relied on the  application  of  the  Bags-of-Features  (BoF)  approach  to  acoustic  echograms.  This approach  is  widely  exploited  for  pattern  recognition  issues  and  naturally  applies here, considering  fish  schools  as  the  relevant  elementary  objects.  It  relies  on the  extraction  and categorization  of  fish  schools  in  fisheries  acoustic  data.  Echogram  descriptors  were computed  per  unit  echogram  length  as  the  numbers  of  schools,  in  different  school categories.  We  applied  this  approach  to  the  discrimination  of  juvenile  and  adult  anchovy (Engraulis  ringens)  off  Peru.  Whereas  the  discrimination  of  individual  schools  is  low (below  70%),  the  proposed  BoF  scheme  achieved  between  89%  and  92%  of  correct classification of juvenile and adult echograms for different survey datasets and significantly outperformed classical school-based echogram characteristics (about 10% of improvement of the correct classification rate). We further illustrate the potential of the proposed scheme for the estimation of the spatial distribution of juvenile and adult anchovy populations. /<p>',	
	ronan_title:'<cite>Bags-of-Features for fish school cluster characterization in pelagic ecosystems: application to the discrimination of juvenile and adult anchovy (Engraulis ringens) clusters off Peru</cite> <br> 2012 Canadian Journal of Fisheries and Aquatic Sciences'	
	};
	 
function fonction(paper){
	if(paper.getAttribute("value")==="title"){
		paper.innerHTML=abstracts[paper.getAttribute("conf").concat("_title")].concat(abstracts[paper.getAttribute("conf").concat("_abstract")]);
		paper.setAttribute("value","abstract");
	}
	else{
		paper.innerHTML=abstracts[paper.getAttribute("conf").concat("_title")];
		paper.setAttribute("value","title");				
	}
}
</script>

<div class="content">
<ul class="menu">
      <li><a href="index.html">Home</a></li>
      <li><a href="#publi">Publications</a></li>
      <li><a href="#highlights">Research highlights</a></li>
      <li><a href="#software">Software</a></li>
      <li><a href="#teaching">Teaching activity</a></li>
</ul>  
  <div class="main_content">
    <div class="sd_right">
      <div class="text_padding">
        <img height="155" width="120" src="images/face.jpg"> 
        <h2>Paul Gay</h2>
				Computer vision, multimedia indexing and graph analysis<br>
        <a onmouseover="this.style.cursor='pointer'" onclick="this.innerHTML='paul.gay@univ-pau.fr'"><b>Click to reveal email</b></a><br>
        <a href="https://www.linkedin.com/in/paul-gay-8002781b5/">LinkedIn</a>
	<br>
	<a href="https://scholar.google.fr/citations?user=TwBT4HEAAAAJ">Google Scholar Profile</a>
      </div>
    </div>
    <div class="sd_left">
      <div class="text_padding">
	I am a research engineer working at the <a href="https://greenai-uppa.github.io/">GreenAI Uppa</a> team where I study environmental impacts of AI, and environmental applications of IA. I am involved in different projects including NLP applications for social sciences, fish counting on videos, multimedia indexing for crisis management. This year, I joined the <a href="https://www.lisn.upsaclay.fr/"> LISN laboratory </a> where I am involved in  <a href="https://greenai-uppa.github.io/Coca4AI/">carbon footprint study of the lab-ia data center</a>.
	      <br>
	      <h2>Welcome Visitor! Here are the latest news : </h2>
        <ul>
        <li>Join us the 1/12 at <a href="http://iapau.org/"> IAPau 5</a> conference on Generative IA!
        <li>5/6/2023 : <a href="https://gsha2023.sciencesconf.org/">Join us</a> at the Green Software and Human Actors Workshop where I'll present our work on the <a href="https://greenai-uppa.github.io/Coca4AI/"> Coca4AI</a> project where we measure environmental cost of data centers. </li>
        <li>Check our <a href="https://greenai-uppa.github.io/AIPowerMeter/">AIPowerMeter</a> software: Yet another toolbox to measure the energy consumption of your AI.
        <li>Small video for a flavour of our <a href="https://www.youtube.com/watch?v=IedJytgIFE0"> Social Computing Work</a> in collaboration with the <a href="tree.univ-pau.fr/">Tree lab</a> (in french).
				<ul>
        <a name="biblio"> </a> 
        <br>
        <br>
        <h2>The story behind <a href="Paul_Gay_resume.pdf" style="color: #660099">my resume</a></h2>
  </br>
  <a class=parttitle>R&D Engineer 2019-2020:</a> Two entertaining years at LumenAI start-up where I worked on document indexing with large industrial companies and graph analysis problems like community detection. 
	<br>
	<a class=parttitle>Late 2018:</a> Before getting back into research, I went into some travelling, among other things, to practice my watercolors. You can see some samples <a href=aquarelles.html>there</a>.
	<br>
	<a class=parttitle>Post-doc in Italy: 2016-2018</a> I was a post-doctoral fellow at IIT/PAVIS (Genova Italy) with <a href=http://users.isr.ist.utl.pt/~adb/>Alessio Del Bue</a>,  where I worked on merging multiple view geometry and machine learning. I created <a href="https://paulgay.github.io/highlight-vgm.html">PSFMO</a> to include probabilistic prior into 3D object reconstruction. <!-- <a href="https://www.youtube.com/watch?v=i7ierVkXYa8">structure from motion</a> and motion segmentation.-->  I also built the first <a href="https://paulgay.github.io/highlight-vgm_gnn.html">Visual Graphs from Motion</a>, a model which understands a 3D scene by localizing the objects, estimate their occupancy and recognize the relations between them. 
        <br>
        <a class=parttitle>Avignon teaching period: 2014-2015 </a> During the school year 2014-2015, I was a teaching assistant (ATER) at Avignon university and member of the <a target="_blank" href="http://lia.univ-avignon.fr/">LIA</a> lab. 
        <br> 
        <a class=parttitle>Phd: 2011-2014</a> After this warm up, I started a phd under the supervision of Sylvain Meigner (<a href="www-lium.univ-lemans.fr">LIUM</a>, France) and Jean Marc Odobez (<a href="http://www.idiap.ch/">IDIAP Research Institute</a>, Switzerland). My research there focused on unsupervised Audio-visual person identification in broadcast data. The major part of this work consisted in improving speaker diarization and face clustering systems. I used probabilistic graphical models to integrate the different modalities in a global framework. This work took place in the context of the <a href="http://www.defi-repere.fr/">REPERE evaluation campaign</a> and the european project <a href=https://www.eumssi.eu/>EUMSSI</a>.
	<br>
	<a class=parttitle>Studies: 2006-2011 </a> I graduated in computer sciences from <a href="http://asi.insa-rouen.fr/">INSA Rouen</a> (France) in 2011 and obtained at the same time a M. of Sciences from university of Rouen. There I discovered machine learning, and get involved in the research projects of the <a href=http://www.litislab.fr/>LITIS laboratory</a>. To complete this master, I had the chance to found an internship position with <a href=https://perso.telecom-bretagne.eu/ronanfablet/>Ronan Fablet</a>, in Peru, on the classification of underwater animals in acoustic data.
	<br>
        <h2>Research highlights <a name="highlights"> </a></h2>
        The Pavis/VGM group has a strong expertise in geometry and 3D reconstruction. When I joined them in 2016, recent efforts tend to merge their expertise in geometry with machine learning techniques to produce representations which can model both the structure (e.g. the 3D shape) and the semantic (e.g. object labels) of the scene. My two main contributions are:
        <ul>
        <li> <a href="highlight-vgm.html">PSfMO</a> a probabilistic method to impose prior on object reconstruction (<a href="https://gitlab.iit.it/pgay/affine_psfmo">code</a>)</li>
        <li> <a href="highlight-vgm_gnn.html">VGfM</a> a geometry aware Graph neural network designed to detect object relationships in 3D scene.</li>
        </ul>
        <br>

        <h2>Publications <a style="color:black;font: 0.65em Arial, sans-serif">(click on titles for abstracts, download links and code)</a> <a name="publi"> </a> </h2>
        <h3>2016-2018: 3D visual scene understanding </h3>
        <a onmouseover="this.style.cursor='pointer'" conf="accv" value="title" onclick="fonction(this)">
	<cite>Visual Graphs from Motion (VGfM): Scene understanding with object geometry reasoning</cite> <br>
	2018 ACCV, (Asian Conference on Computer Vision)
	</a>	
	<br>
	<br>
        <a onmouseover="this.style.cursor='pointer'" conf="iccv" value="title" onclick="fonction(this)">
		<cite>Probabilistic Structure from Motion with Objects </cite> <br>
        2017 ICCV, (International Conference on Computer Vision)
        </a>
        <br>
        <br>
        <a onmouseover="this.style.cursor='pointer'" conf="cviu" value="title" onclick="fonction(this)"> 
        <cite> Factorization based Structure from Motion with Object Priors</cite> <br>
        2017 CVIU (Computer Vision and Image Understanding) 
        </a>

        <h3 >2014-2011: audio-visual people indexing in broadcast news</h3>
        Phd thesis (in french): <a href="these_paul_gay.pdf">Audiovisual segmentation and identification of persons in broadcast news.</a>
        <br>
        <br>
        <a onmouseover="this.style.cursor='pointer'" conf="frontiers" value="title" onclick="fonction(this)"> 
        <cite> CRF-Based Context Modeling for Person Identification in Broadcast Videos </cite> <br> 
        2015 Frontiers journal in ICT
        </a>

        <br>
        <br>        
        <a onmouseover="this.style.cursor='pointer'" conf="cbmi" value="title" onclick="fonction(this)"> 
        <cite> Comparison of Two Methods for Unsupervised Person Identification in TV Shows </cite> <br>
        2014 CBMI (IEEE worshop on Content based Multimedia Indexing) 
        </a>
        <br>
        <br>
        <a onmouseover="this.style.cursor='pointer'"  conf="icip" value="title" onclick="fonction(this)">  
        <cite>A conditional random field approach in broadcast news using overlaid texts</cite> <br>
        2014 ICIP (IEEE International Conference on Image Processing)
        </a> 
        <br>
        <br>
        <a onmouseover="this.style.cursor='pointer'"  conf="icassp" value="title" onclick="fonction(this)">
		    <cite>A conditional random field approach for audio-visual people diarization</cite> <br>
        2014 ICASSP (International Conference on Acoustic Speech and Signal Processing)
        </a>        
        <br>
        <br>
        <a onmouseover="this.style.cursor='pointer'"  conf="interspeech" value="title" onclick="fonction(this)">
		    <cite>An open-source state-of-the-art toolbox for broadcast news diarization</cite> <br>
        2013 INTERSPEECH (Conference of the International Speech Communication Association)
        </a> 
        <br>
        <br>
        <a onmouseover="this.style.cursor='pointer'"  conf="icmr" value="title" onclick="fonction(this)">
        <cite>Fusing matching and biometric similarity measures for face diarization in video</cite> <br>
        2013 ICMR (IEEE International Conference on Multimedia Retrieval)
        </a>
        <br>
        <h2>Software<a name="software"> </a></h2> 

         <ul>
		 <li><a href="https://github.com/GreenAI-Uppa/AIPowerMeter">AIPowerMeter</a> A simple tool to record the power consumption of your python programs (Intel CPU and Nvidia GPU).</li>
		 <li><a href="https://github.com/paulgay/sfmo_py">SfMO in python</a> I implemented a python version of the CVPR Structure from Motion with Objects paper, mostly as a material for my computer vision classes.</li>
		 <li>There is a <a href="https://github.com/paulgay/VGfM">github</a> for the code of our ACCV paper. Unfortunately, it is not simple to use as you have to press more than one button. 
		 <li><a href="https://gitlab.iit.it/pgay/lfd_lfdc_plfd">LfD method</a> i.e. 3D location with perspective cameras, developped mainly by Cosimo Rubino and detailed in his 2018 PAMI. I added two improved versions: LfDc which uses additional linear constraints and has more accurate results (see our ACCV 2018 paper), and PLfDc which uses both constraints and the prior developed for PSfMO. </li>
		      
		        <li><a href="https://gitlab.iit.it/pgay/affine_psfmo">PSfMO</a> detailed in our ICCV 2017 paper</li>
		</ul>         
        <h2>Teaching Activity<a name="teaching"> </a> </h2>
					A small subset of my Cytech 2020 classes : Deep learning for engineers (in french)
         <ul>
  			<li><a href="cours_ti1.html">slides</a>: background in image processing </li>
  			<li><a href="cours_ti2.html">slides</a>: Geometry and structure from motion </li>
  			<li><a href="cours_ti2.html">slides</a>: Geometry and structure from motion </li>
		</ul>        
		<a href="manipulation_pourcentage.pdf">Statistic manipulation</a> Maths and physics classes in high school (in french)
           <br>
           <br>
           <br>
      </div>
    </div>
  </div>
</div>
</body>
</html>
